# ğŸ” BiLSTM-based Named Entity Recognition (NER)

This project implements a **token-level Named Entity Recognition (NER)** system using:
- NLTK for text preprocessing  
- Word2Vec for vector embeddings  
- Bi-directional LSTM + TimeDistributed dense output layer for sequence labeling  

The model predicts BIO-tagged entity labels such as person, organization, location, geopolitical entity, etc.

---

## âœ¨ Features
âœ… Token-level NER  
âœ… BiLSTM architecture  
âœ… Word2Vec embeddings  
âœ… NLTK preprocessing (tokenize, stem, lemmatize)  
âœ… Masking + padded sequences  
âœ… Early stopping during training  

---

## ğŸ§  Pipeline
1) Load dataset (sentences + corresponding tags)  
2) NLTK cleaning (stopwords, lemmatization)  
3) Train Word2Vec embeddings  
4) Encode tokens + tags  
5) Pad sequences  
6) Train BiLSTM model  
7) Predict BIO tags  

---

## ğŸ“¦ Installation

git clone https://github.com/<your-username>/bilstm-ner-nlp
cd bilstm-ner-nlp
pip install -r requirements.txt

## â–¶ï¸ Training

python train.py

## ğŸ“ Model Architecture

Embedding (Word2Vec)
â†’ Masking
â†’ BiLSTM (return_sequences=True)
â†’ TimeDistributed(Dense â†’ softmax)

## âœ… Improvements

Replace Word2Vec with contextual embeddings (BERT)

Add CRF output layer

Add support for more tag formats

Deploy via API

## ğŸ“„ License
MIT
